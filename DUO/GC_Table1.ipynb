{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, synthetic data is generated for CUB 2014 data. This dataset contains group level characteristics of students (n=248.649) that were registered to receive a college grant on 01-02-2014. Due to insufficient processing memory, 25.000 synthetic data points are generated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Import libraries and data\n",
    "1. Data description\n",
    "2. Data cleaning\n",
    "3. Correlation plot\n",
    "4. Stratified sample\n",
    "5. Creating metadata\n",
    "6. Gaussian copula fitting\n",
    "7. Evaluating produced synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "from sdmetrics.reports.single_table import QualityReport\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sdv.metadata import SingleTableMetadata, MultiTableMetadata\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sdmetrics.visualization import get_column_plot,set_plotly_config\n",
    "from sdv.evaluation.single_table import run_diagnostic, evaluate_quality\n",
    "from sdmetrics.single_table import MulticlassDecisionTreeClassifier, CategoricalCAP, CategoricalEnsemble, NumericalSVR, MulticlassMLPClassifier\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data\n",
    "path = 'L:\\\\Werkgroepen\\\\Extern onderzoek Uitwonende Beurs Controle\\\\Algorithm Audit\\\\Gegevenslevering\\\\Werkplan extern CBS\\\\20240220\\\\Tabel1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:37.271915Z",
     "start_time": "2024-05-25T17:31:36.688460Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(path, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:37.364556Z",
     "start_time": "2024-05-25T17:31:37.274023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Translate column names to EN\n",
    "df = df.rename(columns={'PERSOONID': 'Person ID',\n",
    "                        'ONDERWIJSVORM': 'Education',\n",
    "                        'LEEFTIJD': 'Age',\n",
    "                        'AFSTAND_OUDERS': 'Distance',\n",
    "                        'RISICOCATEGORIE': 'Risk category',\n",
    "                        'GESELECTEERD_VOOR_CONTROLE': 'Selected for control',\n",
    "                        'UITKOMST_CONTROLE': 'Outcome house visit',\n",
    "                        'BEZWAARPROCEDURE': 'Appeal',\n",
    "                        'UITKOMST_BEZWAARPROCEDURE': 'Outcome appeal'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:37.524762Z",
     "start_time": "2024-05-25T17:31:37.367799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Translate value of columns to EN\n",
    "df['Selected for control'] = df['Selected for control'].map({'Niet': 'No', 'Wel': 'Yes'})\n",
    "df['Outcome house visit'] = df['Outcome house visit'].map({'Onrechtmatig': 'Unduly', 'Rechtmatig': 'Duly', 'Onbekend': 'unknown'})\n",
    "df['Appeal'] = df['Appeal'].map({'Niet': 'No appeal', 'Wel': 'Appeal'})\n",
    "df['Outcome appeal'] = df['Outcome appeal'].map({'Niet geslaagd': 'Unduly, appeal not successful', 'Geslaagd': 'Unduly, appeal successful', 'Deels geslaagd': 'Unduly, appeal partly successful'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:37.646195Z",
     "start_time": "2024-05-25T17:31:37.528048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person ID                    0\n",
      "Education                    0\n",
      "Age                          0\n",
      "Distance                 38657\n",
      "Risk category                0\n",
      "Selected for control         0\n",
      "Outcome house visit     245470\n",
      "Appeal                       0\n",
      "Outcome appeal          247726\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing values per column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:37.745531Z",
     "start_time": "2024-05-25T17:31:37.701098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248649, 9)\n"
     ]
    }
   ],
   "source": [
    "# Shape of dataframe\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:37.830700Z",
     "start_time": "2024-05-25T17:31:37.751999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person ID</th>\n",
       "      <th>Education</th>\n",
       "      <th>Age</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Risk category</th>\n",
       "      <th>Selected for control</th>\n",
       "      <th>Outcome house visit</th>\n",
       "      <th>Appeal</th>\n",
       "      <th>Outcome appeal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>HBO</td>\n",
       "      <td>21-22</td>\n",
       "      <td>50-500km</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No appeal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>MBO 3-4</td>\n",
       "      <td>19-20</td>\n",
       "      <td>10-20km</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No appeal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>955</td>\n",
       "      <td>HBO</td>\n",
       "      <td>25-50</td>\n",
       "      <td>1m-1km</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No appeal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1078</td>\n",
       "      <td>WO</td>\n",
       "      <td>23-24</td>\n",
       "      <td>50-500km</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No appeal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1081</td>\n",
       "      <td>WO</td>\n",
       "      <td>23-24</td>\n",
       "      <td>50-500km</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No appeal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Person ID Education    Age  Distance  Risk category Selected for control  \\\n",
       "0         72       HBO  21-22  50-500km              5                   No   \n",
       "1         82   MBO 3-4  19-20   10-20km              3                   No   \n",
       "2        955       HBO  25-50    1m-1km              2                   No   \n",
       "3       1078        WO  23-24  50-500km              5                   No   \n",
       "4       1081        WO  23-24  50-500km              5                   No   \n",
       "\n",
       "  Outcome house visit     Appeal Outcome appeal  \n",
       "0                 NaN  No appeal            NaN  \n",
       "1                 NaN  No appeal            NaN  \n",
       "2                 NaN  No appeal            NaN  \n",
       "3                 NaN  No appeal            NaN  \n",
       "4                 NaN  No appeal            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview of data\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:37.960036Z",
     "start_time": "2024-05-25T17:31:37.838697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person ID                int64\n",
       "Education               object\n",
       "Age                     object\n",
       "Distance                object\n",
       "Risk category            int64\n",
       "Selected for control    object\n",
       "Outcome house visit     object\n",
       "Appeal                  object\n",
       "Outcome appeal          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of all columns types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:38.509622Z",
     "start_time": "2024-05-25T17:31:38.301660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Distance\n",
       "50-500km    84972\n",
       "20-50km     43616\n",
       "NaN         38657\n",
       "2-5km       20517\n",
       "10-20km     19527\n",
       "5-10km      16087\n",
       "1m-1km      13080\n",
       "1-2km       11248\n",
       "0km           945\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts before filling missing values\n",
    "df['Distance'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:38.732586Z",
     "start_time": "2024-05-25T17:31:38.531309Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filling missing values for Distance\n",
    "df['Distance'].fillna('Not available', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:38.962204Z",
     "start_time": "2024-05-25T17:31:38.756647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Distance\n",
       "50-500km         84972\n",
       "20-50km          43616\n",
       "Not available    38657\n",
       "2-5km            20517\n",
       "10-20km          19527\n",
       "5-10km           16087\n",
       "1m-1km           13080\n",
       "1-2km            11248\n",
       "0km                945\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts after filling missing values\n",
    "df['Distance'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:39.080601Z",
     "start_time": "2024-05-25T17:31:38.984028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome house visit\n",
       "Duly       1566\n",
       "Unduly     1238\n",
       "unknown     375\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts before filling missing values\n",
    "df['Outcome house visit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform risk category from numeric to categorical data\n",
    "df['Risk category'] = df['Risk category'].astype('category',copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:39.194940Z",
     "start_time": "2024-05-25T17:31:39.085922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filling missing values\n",
    "df['Outcome house visit'].fillna('Not available', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:39.298610Z",
     "start_time": "2024-05-25T17:31:39.201436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome house visit\n",
       "Not available    245470\n",
       "Duly               1566\n",
       "Unduly             1238\n",
       "unknown             375\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts after filling missing values\n",
    "df['Outcome house visit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:39.389814Z",
     "start_time": "2024-05-25T17:31:39.303946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome appeal\n",
       "Unduly, appeal not successful       711\n",
       "Unduly, appeal successful           194\n",
       "Unduly, appeal partly successful     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts before filling missing values\n",
    "df['Outcome appeal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:39.496232Z",
     "start_time": "2024-05-25T17:31:39.394149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filling missing values in Appeal\n",
    "df['Appeal'].fillna('No appeal', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:39.574550Z",
     "start_time": "2024-05-25T17:31:39.503444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Appeal\n",
       "No appeal    247726\n",
       "Appeal          923\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts after filling missing values\n",
    "df['Appeal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:39.685338Z",
     "start_time": "2024-05-25T17:31:39.583929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing columns selected for control, appeal and person ID\n",
    "del df['Selected for control']\n",
    "del df['Appeal']\n",
    "del df['Person ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:39.813207Z",
     "start_time": "2024-05-25T17:31:39.690626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education                   0\n",
       "Age                         0\n",
       "Distance                    0\n",
       "Risk category               0\n",
       "Outcome house visit         0\n",
       "Outcome appeal         247726\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking remaining missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:40.037488Z",
     "start_time": "2024-05-25T17:31:39.817471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for column 'Education':\n",
      "Education\n",
      "HBO        107852\n",
      "WO          95655\n",
      "MBO 3-4     33563\n",
      "MBO 1-2     11579\n",
      "Name: count, dtype: int64\n",
      "Value counts for column 'Age':\n",
      "Age\n",
      "21-22    85675\n",
      "19-20    76439\n",
      "23-24    43106\n",
      "25-50    26109\n",
      "15-18    17320\n",
      "Name: count, dtype: int64\n",
      "Value counts for column 'Distance':\n",
      "Distance\n",
      "50-500km         84972\n",
      "20-50km          43616\n",
      "Not available    38657\n",
      "2-5km            20517\n",
      "10-20km          19527\n",
      "5-10km           16087\n",
      "1m-1km           13080\n",
      "1-2km            11248\n",
      "0km                945\n",
      "Name: count, dtype: int64\n",
      "Value counts for column 'Outcome house visit':\n",
      "Outcome house visit\n",
      "Not available    245470\n",
      "Duly               1566\n",
      "Unduly             1238\n",
      "unknown             375\n",
      "Name: count, dtype: int64\n",
      "Value counts for column 'Outcome appeal':\n",
      "Outcome appeal\n",
      "Unduly, appeal not successful       711\n",
      "Unduly, appeal successful           194\n",
      "Unduly, appeal partly successful     18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distinguish categorical and numerical columns\n",
    "# Select only the categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object'])\n",
    "\n",
    "# Loop through each categorical column and print value counts\n",
    "for column in categorical_columns.columns:\n",
    "    print(f\"Value counts for column '{column}':\")\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. Stratified sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Create a stratified sample from the original dataset with 25.000 samples. This data will be used to create the synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:31:44.591146Z",
     "start_time": "2024-05-25T17:31:40.883290Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Education    Age       Distance Risk category Outcome house visit  \\\n",
      "19042        HBO  21-22         5-10km             2       Not available   \n",
      "203255       HBO  25-50       50-500km             5       Not available   \n",
      "30144        HBO  21-22       50-500km             5       Not available   \n",
      "198601       HBO  21-22  Not available             6       Not available   \n",
      "203578   MBO 3-4  19-20         5-10km             2       Not available   \n",
      "...          ...    ...            ...           ...                 ...   \n",
      "31720         WO  23-24        20-50km             5       Not available   \n",
      "9474     MBO 3-4  15-18        20-50km             4       Not available   \n",
      "242299        WO  21-22  Not available             6       Not available   \n",
      "235925   MBO 3-4  19-20  Not available             6       Not available   \n",
      "146764        WO  25-50       50-500km             5       Not available   \n",
      "\n",
      "       Outcome appeal  \n",
      "19042             NaN  \n",
      "203255            NaN  \n",
      "30144             NaN  \n",
      "198601            NaN  \n",
      "203578            NaN  \n",
      "...               ...  \n",
      "31720             NaN  \n",
      "9474              NaN  \n",
      "242299            NaN  \n",
      "235925            NaN  \n",
      "146764            NaN  \n",
      "\n",
      "[20000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the number of samples to have\n",
    "n_samples = 20000\n",
    "n_samples_form = f'{int(n_samples/1000)}' + 'k'\n",
    "\n",
    "# Ensure df has enough rows to sample from\n",
    "if len(df) < n_samples:\n",
    "    raise ValueError(\"The dataset does not have enough samples.\")\n",
    "\n",
    "# Combine the columns to form a stratification key\n",
    "stratify_cols = list(df.columns)\n",
    "df['stratify_key'] = df[stratify_cols].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Filter out groups with less than 2 members\n",
    "value_counts = df['stratify_key'].value_counts()\n",
    "sufficient_counts = value_counts[value_counts >= 2].index\n",
    "df_filtered = df[df['stratify_key'].isin(sufficient_counts)]\n",
    "\n",
    "# Recalculate n_samples based on the filtered dataset size\n",
    "if len(df_filtered) < n_samples:\n",
    "    raise ValueError(\"The filtered dataset does not have enough samples.\")\n",
    "\n",
    "# Create the stratified sample\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=n_samples, random_state=42)\n",
    "for _, sample_index in split.split(df_filtered, df_filtered['stratify_key']):\n",
    "    stratified_sample = df_filtered.iloc[sample_index]\n",
    "\n",
    "# Drop the stratification key column if not needed\n",
    "stratified_sample = stratified_sample.drop(columns=['stratify_key'])\n",
    "df = df.drop(columns=['stratify_key'])\n",
    "print(stratified_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:33:18.706304Z",
     "start_time": "2024-05-25T17:33:18.260727Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df[[column]].value_counts(normalize = True) =Education\n",
      "HBO          0.433752\n",
      "WO           0.384699\n",
      "MBO 3-4      0.134981\n",
      "MBO 1-2      0.046568\n",
      "Name: proportion, dtype: float64\n",
      "stratified_sample[[column]].value_counts(normalize = True) =Education\n",
      "HBO          0.43340\n",
      "WO           0.38515\n",
      "MBO 3-4      0.13490\n",
      "MBO 1-2      0.04655\n",
      "Name: proportion, dtype: float64\n",
      "df[[column]].value_counts(normalize = True) =Age  \n",
      "21-22    0.344562\n",
      "19-20    0.307417\n",
      "23-24    0.173361\n",
      "25-50    0.105003\n",
      "15-18    0.069656\n",
      "Name: proportion, dtype: float64\n",
      "stratified_sample[[column]].value_counts(normalize = True) =Age  \n",
      "21-22    0.34455\n",
      "19-20    0.30740\n",
      "23-24    0.17350\n",
      "25-50    0.10480\n",
      "15-18    0.06975\n",
      "Name: proportion, dtype: float64\n",
      "df[[column]].value_counts(normalize = True) =Distance     \n",
      "50-500km         0.341735\n",
      "20-50km          0.175412\n",
      "Not available    0.155468\n",
      "2-5km            0.082514\n",
      "10-20km          0.078532\n",
      "5-10km           0.064698\n",
      "1m-1km           0.052604\n",
      "1-2km            0.045236\n",
      "0km              0.003801\n",
      "Name: proportion, dtype: float64\n",
      "stratified_sample[[column]].value_counts(normalize = True) =Distance     \n",
      "50-500km         0.34205\n",
      "20-50km          0.17555\n",
      "Not available    0.15520\n",
      "2-5km            0.08235\n",
      "10-20km          0.07860\n",
      "5-10km           0.06465\n",
      "1m-1km           0.05275\n",
      "1-2km            0.04525\n",
      "0km              0.00360\n",
      "Name: proportion, dtype: float64\n",
      "df[[column]].value_counts(normalize = True) =Risk category\n",
      "5                0.341699\n",
      "4                0.265012\n",
      "6                0.136940\n",
      "2                0.104794\n",
      "3                0.084235\n",
      "1                0.067320\n",
      "Name: proportion, dtype: float64\n",
      "stratified_sample[[column]].value_counts(normalize = True) =Risk category\n",
      "5                0.34205\n",
      "4                0.26530\n",
      "6                0.13645\n",
      "2                0.10480\n",
      "3                0.08425\n",
      "1                0.06715\n",
      "Name: proportion, dtype: float64\n",
      "df[[column]].value_counts(normalize = True) =Outcome house visit\n",
      "Not available          0.987215\n",
      "Duly                   0.006298\n",
      "Unduly                 0.004979\n",
      "unknown                0.001508\n",
      "Name: proportion, dtype: float64\n",
      "stratified_sample[[column]].value_counts(normalize = True) =Outcome house visit\n",
      "Not available          0.98890\n",
      "Duly                   0.00590\n",
      "Unduly                 0.00405\n",
      "unknown                0.00115\n",
      "Name: proportion, dtype: float64\n",
      "df[[column]].value_counts(normalize = True) =Outcome appeal                  \n",
      "Unduly, appeal not successful       0.770314\n",
      "Unduly, appeal successful           0.210184\n",
      "Unduly, appeal partly successful    0.019502\n",
      "Name: proportion, dtype: float64\n",
      "stratified_sample[[column]].value_counts(normalize = True) =Outcome appeal               \n",
      "Unduly, appeal not successful    0.852459\n",
      "Unduly, appeal successful        0.147541\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Evaluate value counts of original data to stratified sample\n",
    "for column in df.columns:\n",
    "    print(f'{df[[column]].value_counts(normalize = True) =}')\n",
    "    print(f'{stratified_sample[[column]].value_counts(normalize = True) =}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:33:27.206050Z",
     "start_time": "2024-05-25T17:33:27.199435Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of samples \n",
    "len(stratified_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Creating metadata is necessary for sdv package which we will use for the Gaussian copula. This metadata contains a representation of the column types and the type of data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:33:48.206919Z",
     "start_time": "2024-05-25T17:33:48.103563Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing metadata generator\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(stratified_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T17:34:05.354023Z",
     "start_time": "2024-05-25T17:34:05.334518Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata.validate()\n",
    "metadata.save_to_json(f'Tabel1_stratified_sample{n_samples_form}_metadata.json') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gaussian copula fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "A copula is a multivariate CDF, with uniform distributed marginals. This means that it encapsulates the joint distribution of the data. Our goal in using a copula for synthetic data generation, is to understand the joint distribution of the data and then generate samples from that joint distribution.\n",
    "\n",
    "The copula does not assume a specific form for the marginal distributions of each column, and allows us to seperate the estimation of the marginal distributions from that of the joint distribution. It works in two steps:\n",
    "\n",
    "1. The marginal distribution of each column is estimated, by using a Gaussian kernel density function (gaussian_kde). The samples are then transformed to a uniform distribution by using the probability integral transformation.\n",
    "2. A joint Gaussian distribution is fitted on the (pseudo) transformed samples.\n",
    "By using a Gaussian copula, we are making some assumptions about the dependence structure of the data. In particular, regarding tail dependence, and how likely it is to have extreme values for the numeric variables happen at the same time.\n",
    "\n",
    "Produce the synthetic data using a Gaussian Coupola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:38:45.278449Z",
     "start_time": "2024-05-25T17:34:19.955405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Produce the synthetic data using a gaussian copula\n",
    "# Gaussian copula fitting\n",
    "synthesizer = GaussianCopulaSynthesizer(metadata,  default_distribution=\"gaussian_kde\")\n",
    "synthesizer.fit(stratified_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Once the copula is fitted to the original data, we can sample as many synthetic data points as we want from the joint CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T19:28:57.211186Z",
     "start_time": "2024-05-25T18:38:45.447893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Age</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Risk category</th>\n",
       "      <th>Outcome house visit</th>\n",
       "      <th>Outcome appeal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MBO 3-4</td>\n",
       "      <td>19-20</td>\n",
       "      <td>5-10km</td>\n",
       "      <td>5</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WO</td>\n",
       "      <td>25-50</td>\n",
       "      <td>50-500km</td>\n",
       "      <td>4</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MBO 3-4</td>\n",
       "      <td>19-20</td>\n",
       "      <td>50-500km</td>\n",
       "      <td>5</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WO</td>\n",
       "      <td>21-22</td>\n",
       "      <td>20-50km</td>\n",
       "      <td>6</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WO</td>\n",
       "      <td>19-20</td>\n",
       "      <td>50-500km</td>\n",
       "      <td>2</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Education    Age  Distance Risk category Outcome house visit Outcome appeal\n",
       "0   MBO 3-4  19-20    5-10km             5       Not available            NaN\n",
       "1        WO  25-50  50-500km             4       Not available            NaN\n",
       "2   MBO 3-4  19-20  50-500km             5       Not available            NaN\n",
       "3        WO  21-22   20-50km             6       Not available            NaN\n",
       "4        WO  19-20  50-500km             2       Not available            NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create synthetic data and preview head\n",
    "synthetic_data_GC = synthesizer.sample(num_rows=n_samples)\n",
    "synthetic_data_GC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T19:28:57.508265Z",
     "start_time": "2024-05-25T19:28:57.287802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store synthetic data\n",
    "synthetic_data_GC.to_csv(f'Table1_SD_{n_samples_form}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluating produced synthetic data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The diagnostic reports data validity and structure. Data validity means that primary keys must be unique and non-null; continuous values in the synthetic data must adhere to the min/max range in the real data; discrete values in the synthetic data must adhere to the same categories as the real data. Data structure checks that the real and synthtetic data have the same column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:16:40.616748Z",
     "start_time": "2024-05-26T10:16:39.204110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 15.12it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic test to check on structure of data\n",
    "diagnostic = run_diagnostic(\n",
    "    real_data=df,\n",
    "    synthetic_data=synthetic_data_GC,\n",
    "    metadata=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The column shape checks how close the marginal distributions for the real and synthetic data are. Column pair trendschecks the statistical similarity between pairs of columns in the real and synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:16:52.082685Z",
     "start_time": "2024-05-26T10:16:47.288448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 22.74it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|███████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.41it/s]\n",
      "\n",
      "Overall Score: 88.14%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 86.4%\n",
      "- Column Pair Trends: 89.88%\n"
     ]
    }
   ],
   "source": [
    "# Check univariate and bivariate distributions\n",
    "quality_report = evaluate_quality(\n",
    "    df,\n",
    "    synthetic_data_GC,\n",
    "    metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:16:53.697436Z",
     "start_time": "2024-05-26T10:16:53.679283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Education</td>\n",
       "      <td>TVComplement</td>\n",
       "      <td>0.995817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>TVComplement</td>\n",
       "      <td>0.992268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Distance</td>\n",
       "      <td>TVComplement</td>\n",
       "      <td>0.979802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Risk category</td>\n",
       "      <td>TVComplement</td>\n",
       "      <td>0.918911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outcome house visit</td>\n",
       "      <td>TVComplement</td>\n",
       "      <td>0.988079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Outcome appeal</td>\n",
       "      <td>TVComplement</td>\n",
       "      <td>0.309226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Column        Metric     Score\n",
       "0            Education  TVComplement  0.995817\n",
       "1                  Age  TVComplement  0.992268\n",
       "2             Distance  TVComplement  0.979802\n",
       "3        Risk category  TVComplement  0.918911\n",
       "4  Outcome house visit  TVComplement  0.988079\n",
       "5       Outcome appeal  TVComplement  0.309226"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Univariate quality report\n",
    "quality_report.get_details('Column Shapes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "For numerical columns, The KSComplement returns 1-(KS statistics) where the Kolmogorov Smirnov (KS) statistic is the maximal difference between the CDF of the variable in the original and the synthetic data. A value close to 1 represents a better fit.\n",
    "\n",
    "For categorical columns, The TVComplement returns 1 - (TV Distance), where the Total Variation Distance measures the relative frequencies of the categories of a given variable in the original and the synthetic data. A value close to 1 represents a better fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:35:18.677104Z",
     "start_time": "2024-05-26T10:35:12.441586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_34.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_34.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_34.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_34.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_34.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare frequency categorical columns synthetic data vs real data\n",
    "categorical_columns = df.select_dtypes(include=object)  # Select object type (categorical) columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    # Check if column has categories (avoid potential errors)\n",
    "    fig = get_column_plot(\n",
    "        real_data=df,\n",
    "        synthetic_data=synthetic_data_GC,\n",
    "        column_name=col,\n",
    "        plot_type='bar'  # Adjust plot_type for categorical data\n",
    "    )\n",
    "    fig.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:17:31.050273Z",
     "start_time": "2024-05-26T10:17:24.064064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compare frequency numerical columns synthetic data vs real data\n",
    "numerical_columns = df.select_dtypes(include=[np.number])\n",
    "for col in numerical_columns:\n",
    "    # Create the plot for each numerical column\n",
    "    fig = get_column_plot(\n",
    "        real_data=df,\n",
    "        synthetic_data=synthetic_data_GC,\n",
    "        column_name=col,\n",
    "        plot_type='distplot'\n",
    "    )\n",
    "    fig.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Statistical tests for univariate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:36:56.167939Z",
     "start_time": "2024-05-26T10:36:56.151355Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education                object\n",
       "Age                      object\n",
       "Distance                 object\n",
       "Risk category          category\n",
       "Outcome house visit      object\n",
       "Outcome appeal           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:37:39.710041Z",
     "start_time": "2024-05-26T10:37:39.555777Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "\n",
    "# Define continuous variables\n",
    "continuous_vars = []\n",
    "\n",
    "# Apply KS test to continuous variables\n",
    "for column in continuous_vars:\n",
    "    ks_statistic, ks_p_value = ks_2samp(df[column], synthetic_data_GC[column])\n",
    "    print(f\"KS Statistic for {column}: {ks_statistic}, P-value: {ks_p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:39:36.275404Z",
     "start_time": "2024-05-26T10:39:36.266796Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Education', 'Age', 'Distance', 'Risk category', 'Outcome house visit',\n",
       "       'Outcome appeal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:40:08.306977Z",
     "start_time": "2024-05-26T10:40:08.162610Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared Statistic for Education: 6.034943731847264, P-value: 0.7364159393170133\n",
      "Chi-squared Statistic for Age: 13.921476741142035, P-value: 0.6045637121365757\n",
      "Chi-squared Statistic for Distance: 56.409684957256914, P-value: 0.7388639674718988\n",
      "Chi-squared Statistic for Risk category: 28.67181574458843, P-value: 0.2778671868513474\n",
      "Chi-squared Statistic for Outcome house visit: 2.126033463564654, P-value: 0.9893140168985204\n",
      "Chi-squared Statistic for Outcome appeal: 0.0, P-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Degfine categorical variables\n",
    "categorical_vars = ['Education', 'Age', 'Distance', 'Risk category', 'Outcome house visit', 'Outcome appeal']\n",
    "\n",
    "# Apply Chi-squared test to categorical variables\n",
    "for column in categorical_vars:\n",
    "    # Create a contingency table\n",
    "    contingency_table = pd.crosstab(df[column], synthetic_data_GC[column])\n",
    "\n",
    "    # Run the Chi-squared test\n",
    "    chi2_stat, chi2_p, dof, ex = chi2_contingency(contingency_table)\n",
    "    print(f\"Chi-squared Statistic for {column}: {chi2_stat}, P-value: {chi2_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Multivariate checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:40:37.704308Z",
     "start_time": "2024-05-26T10:40:35.651518Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # Create subplots for side-by-side comparison\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# # Plot correlation heatmap for the real dataset\n",
    "# sns.heatmap(df.corr(numeric_only=True), cmap='coolwarm', annot=True, fmt=\".2f\", ax=axes[0])\n",
    "# axes[0].set_title('Real Dataset Correlation Heatmap')\n",
    "\n",
    "# # Plot correlation heatmap for the synthetic dataset\n",
    "# sns.heatmap(synthetic_data_GC.corr(numeric_only=True), cmap='coolwarm', annot=True, fmt=\".2f\", ax=axes[1])\n",
    "# axes[1].set_title('Synthetic Dataset Correlation Heatmap')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We can observe that the correlation between the numerical columns in the original and synthetic datasets are very well preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## ML efficacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Some times, the goal of producing synthetic datasets is to solve some downstream machine learning task. This could be a classification problem in our case, so a way to test how well the synthetic datasets are is to split both the original and synthetic datasets into train and test sets. Next, we can fit the ML model to the train portion of the synthetic data and evaluate it on the test portion of the real data. If the synthetic data is close to the real data, then the capability (f1-score) of the model should be high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T11:15:37.443253Z",
     "start_time": "2024-05-26T11:15:22.346612Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# MulticlassMLPClassifier.compute(stratified_sample, synthetic_data_GC, target = 'RISK_SCORE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "First we can check if there are any rows in the original data that are found in the synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:47:36.978383Z",
     "start_time": "2024-05-26T10:47:36.658316Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching rows:  0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any matching rows in the two dataframes\n",
    "matching_rows = df.isin(synthetic_data_GC).all(axis=1)\n",
    "\n",
    "# Print the number of matching rows\n",
    "print(\"Number of matching rows: \", matching_rows.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Next, We can imagine that an attacker already has access to some parts of the dataset. This could e.g. be access to some of the columns in the real data. If the attacker also has access to the full synthetic data, We would like to know how likely it is that they could then recover the remaining original data. It works in the following way\n",
    "\n",
    "Identify a row (let's call it r) in the original dataset. Record all the key fields present in\n",
    "\n",
    "Search through the synthetic dataset to find all rows that share the same key fields as r. This group of rows is referred to as the \"equivalence class\" of r in the synthetic data.\n",
    "\n",
    "Within this equivalence class, each row contains synthetic values for the sensitive fields. Each of these synthetic values \"votes\" to guess the sensitive fields of the original row r.\n",
    "\n",
    "Calculate the final score by determining the frequency of votes that correctly match all sensitive fields of the original row r. This score ranges between 0 and 1, indicating the accuracy of the synthetic data in replicating sensitive field values from the original dataset.\n",
    "\n",
    "A score closer to one indicates that the the attacker is not able to correctly guess any of the sensitive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T10:52:55.078220Z",
     "start_time": "2024-05-26T10:51:34.487895Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03176616825545697"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = CategoricalCAP.compute(\n",
    "    real_data= stratified_sample,\n",
    "    synthetic_data=synthetic_data_GC,\n",
    "    key_fields=['Age'], # the column names that the attacker already knows. \n",
    "    sensitive_fields=['Outcome house visit']  # the column names that the attacker wants to guess.\n",
    ")\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
